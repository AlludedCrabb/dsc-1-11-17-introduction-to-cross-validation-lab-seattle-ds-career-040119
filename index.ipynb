{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Compare the results with normal holdout validation\n",
    "- Apply 5-fold cross validation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "This time, let's only include the variables that were previously selected using recursive feature elimination. We included the code to preprocess below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "b = boston_features[\"B\"]\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_features = pd.DataFrame(boston.data,\n",
    "                               columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.06905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>18.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>2.31000</td>\n",
       "      <td>7.07000</td>\n",
       "      <td>7.07000</td>\n",
       "      <td>2.18000</td>\n",
       "      <td>2.18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.53800</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>0.45800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>6.57500</td>\n",
       "      <td>6.42100</td>\n",
       "      <td>7.18500</td>\n",
       "      <td>6.99800</td>\n",
       "      <td>7.14700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>65.20000</td>\n",
       "      <td>78.90000</td>\n",
       "      <td>61.10000</td>\n",
       "      <td>45.80000</td>\n",
       "      <td>54.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>4.09000</td>\n",
       "      <td>4.96710</td>\n",
       "      <td>4.96710</td>\n",
       "      <td>6.06220</td>\n",
       "      <td>6.06220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>296.00000</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>222.00000</td>\n",
       "      <td>222.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>15.30000</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>18.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>392.83000</td>\n",
       "      <td>394.63000</td>\n",
       "      <td>396.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>4.98000</td>\n",
       "      <td>9.14000</td>\n",
       "      <td>4.03000</td>\n",
       "      <td>2.94000</td>\n",
       "      <td>5.33000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          1          2          3          4\n",
       "CRIM       0.00632    0.02731    0.02729    0.03237    0.06905\n",
       "ZN        18.00000    0.00000    0.00000    0.00000    0.00000\n",
       "INDUS      2.31000    7.07000    7.07000    2.18000    2.18000\n",
       "CHAS       0.00000    0.00000    0.00000    0.00000    0.00000\n",
       "NOX        0.53800    0.46900    0.46900    0.45800    0.45800\n",
       "RM         6.57500    6.42100    7.18500    6.99800    7.14700\n",
       "AGE       65.20000   78.90000   61.10000   45.80000   54.20000\n",
       "DIS        4.09000    4.96710    4.96710    6.06220    6.06220\n",
       "RAD        1.00000    2.00000    2.00000    3.00000    3.00000\n",
       "TAX      296.00000  242.00000  242.00000  222.00000  222.00000\n",
       "PTRATIO   15.30000   17.80000   17.80000   18.70000   18.70000\n",
       "B        396.90000  396.90000  392.83000  394.63000  396.90000\n",
       "LSTAT      4.98000    9.14000    4.03000    2.94000    5.33000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_features.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Perform a train-test-split with a test set of 0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston_features[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']]\n",
    "y = pd.DataFrame(boston.target,columns = ['target'])\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 102 404 102\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and apply the model to the make test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "y_hat_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.86138844,  5.02898019, -0.34475254,  0.01276825, -0.64881231]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.75074913],\n",
       "       [29.63344912],\n",
       "       [23.34760741],\n",
       "       [13.23907803],\n",
       "       [16.18135255],\n",
       "       [22.55885206],\n",
       "       [10.38660804],\n",
       "       [28.66982353],\n",
       "       [13.21678721],\n",
       "       [20.79089427],\n",
       "       [22.67242335],\n",
       "       [28.87300125],\n",
       "       [11.70891666],\n",
       "       [22.48534602],\n",
       "       [21.42937366],\n",
       "       [24.14906347],\n",
       "       [22.47207136],\n",
       "       [24.4972792 ],\n",
       "       [25.44047914],\n",
       "       [18.75454162],\n",
       "       [37.89405202],\n",
       "       [20.69897703],\n",
       "       [18.98305853],\n",
       "       [40.09806905],\n",
       "       [26.22673814],\n",
       "       [18.79320983],\n",
       "       [29.89999204],\n",
       "       [30.3955403 ],\n",
       "       [32.30086003],\n",
       "       [22.85486453],\n",
       "       [22.66885538],\n",
       "       [22.75726679],\n",
       "       [17.65619389],\n",
       "       [34.48404334],\n",
       "       [11.90283791],\n",
       "       [20.51913906],\n",
       "       [16.18061695],\n",
       "       [44.79854844],\n",
       "       [20.09684197],\n",
       "       [25.38737258],\n",
       "       [23.51183595],\n",
       "       [18.2179434 ],\n",
       "       [28.94104202],\n",
       "       [17.79722786],\n",
       "       [18.00772922],\n",
       "       [20.73129007],\n",
       "       [ 2.83089961],\n",
       "       [29.15656109],\n",
       "       [ 4.27823933],\n",
       "       [21.27682559],\n",
       "       [19.47415795],\n",
       "       [26.48641707],\n",
       "       [22.29908199],\n",
       "       [36.10717151],\n",
       "       [19.42031169],\n",
       "       [28.93395309],\n",
       "       [21.46854989],\n",
       "       [19.38287669],\n",
       "       [24.76082096],\n",
       "       [35.56348269],\n",
       "       [21.92108032],\n",
       "       [26.68313988],\n",
       "       [24.59744806],\n",
       "       [35.74959289],\n",
       "       [18.35129628],\n",
       "       [44.38411052],\n",
       "       [ 9.97962556],\n",
       "       [21.847208  ],\n",
       "       [28.89731309],\n",
       "       [21.58820393],\n",
       "       [16.80328504],\n",
       "       [19.81111244],\n",
       "       [32.16643848],\n",
       "       [36.14591307],\n",
       "       [30.60746639],\n",
       "       [25.43234552],\n",
       "       [19.83901296],\n",
       "       [20.83814827],\n",
       "       [26.94050039],\n",
       "       [31.47632357],\n",
       "       [24.16891985],\n",
       "       [25.45718162],\n",
       "       [ 5.60169132],\n",
       "       [20.06813748],\n",
       "       [26.17174798],\n",
       "       [ 7.08132881],\n",
       "       [30.88292667],\n",
       "       [22.16080881],\n",
       "       [35.61587439],\n",
       "       [-3.84907329],\n",
       "       [28.8367381 ],\n",
       "       [27.13659081],\n",
       "       [32.21416736],\n",
       "       [23.58089178],\n",
       "       [30.80630949],\n",
       "       [20.60423242],\n",
       "       [18.6100263 ],\n",
       "       [25.48627397],\n",
       "       [34.85415194],\n",
       "       [16.49661968],\n",
       "       [25.42387581],\n",
       "       [22.99024648]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_error = residuals **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = squared_error.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: let's build it from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross-validation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function k-folds that splits a dataset into k evenly sized pieces.\n",
    "If the full dataset is not divisible by k, make the first few folds one larger then later ones.\n",
    "\n",
    "We want the folds to be a list of subsets of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    #Force data as pandas dataframe\n",
    "    data = pd.DataFrame(data)\n",
    "    num_observations = len(data)\n",
    "    fold_size = num_observations//k\n",
    "    leftovers = num_observations%k\n",
    "    folds = []\n",
    "    start_obs = 0\n",
    "    for fold_n in range(1,k+1):\n",
    "        if fold_n <= leftovers:\n",
    "            #Fold Size will be 1 larger to account for leftovers\n",
    "            fold =  data.iloc[start_obs : start_obs+fold_size+1] \n",
    "            folds.append(fold)\n",
    "            start_obs +=  fold_size + 1\n",
    "        else:\n",
    "            fold =  data.iloc[start_obs : start_obs+fold_size] \n",
    "            folds.append(fold)\n",
    "            start_obs +=  fold_size\n",
    "            \n",
    "    return folds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply it to the Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_data = pd.concat([X.reset_index(drop=True), y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_folds = kfolds(bos_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a linear regression for each fold, and calculate the training and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform linear regression on each and calculate the training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target    32.129721\n",
      "dtype: float64, target    28.41105\n",
      "dtype: float64, target    26.950112\n",
      "dtype: float64, target    18.705423\n",
      "dtype: float64, target    27.974246\n",
      "dtype: float64]\n",
      "[target    11.70713\n",
      "dtype: float64, target    27.160829\n",
      "dtype: float64, target    42.046391\n",
      "dtype: float64, target    77.146314\n",
      "dtype: float64, target    36.712923\n",
      "dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "test_errs = []\n",
    "train_errs = []\n",
    "k=5\n",
    "\n",
    "for n in range(k):\n",
    "    # Split in train and test for the fold\n",
    "    train = pd.concat([fold for i, fold in enumerate(bos_folds) if i!=n])\n",
    "    test = bos_folds[n]\n",
    "    # Fit a linear regression model\n",
    "    linreg.fit(train[X.columns], train[y.columns])\n",
    "    #Evaluate Train and Test Errors\n",
    "    y_hat_train = linreg.predict(train[X.columns])\n",
    "    y_hat_test = linreg.predict(test[X.columns])\n",
    "    train_residuals = y_hat_train - train[y.columns]\n",
    "    test_residuals = y_hat_test - test[y.columns]\n",
    "    train_errs.append(np.mean(train_residuals.astype(float)**2))\n",
    "    test_errs.append(np.mean(test_residuals.astype(float)**2))\n",
    "print(train_errs)\n",
    "print(test_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Now, let's perform 5-fold cross-validation to get the mean squared error through scikit-learn. Let's have a look at the five individual MSEs and explain what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the mean of the MSE over the 5 cross-validations and compare and contrast with the result from the train-test-split case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge on k-fold crossvalidation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
